{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA PROJECT - Amazon data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collection/Analysis of data from Amazon (Reviews and Metadata of products) associated to the thema : ecology, bio, renewable etc... (see keywords vector)\n",
    "\n",
    "<br>\n",
    "\n",
    "__Review data__ : \n",
    "Download http://jmcauley.ucsd.edu/data/amazon/links.html go to 'Per Category Files' section and DL 'reviews' file for a \n",
    "chosen category. (Or the Complete Review Data 18GB) It is better to not take the 5-core data as it contains only 5 reviews for each products (we're missing data)\n",
    "\n",
    ">Features:\n",
    "- reviewerID - ID of the reviewer, e.g. A2SUAM1J3GNN3B\n",
    "- asin - ID of the product, e.g. 0000013714\n",
    "- reviewerName - name of the reviewer\n",
    "- helpful - helpfulness rating of the review, e.g. 2/3\n",
    "- reviewText - text of the review\n",
    "- overall - rating of the product\n",
    "- summary - summary of the review\n",
    "- unixReviewTime - time of the review (unix time)\n",
    "- reviewTime - time of the review (raw)\n",
    "\n",
    "__Metadata (Product)__ : \n",
    "Download http://jmcauley.ucsd.edu/data/amazon/links.html go to 'Per Category Files' section and DL 'metadata' file for a chosen category. (Or the Complete Review Data 18GB) It is better to not take the 5-core data as it contains only 5 reviews for each products (we're missing data)\n",
    "\n",
    "\n",
    ">Features:\n",
    "- asin - ID of the product, e.g. 0000031852\n",
    "- title - name of the product\n",
    "- price - price in US dollars (at time of crawl)\n",
    "- imUrl - url of the product image\n",
    "- related - related products (also bought, also viewed, bought together, buy after viewing)\n",
    "- salesRank - sales rank information\n",
    "- brand - brand name\n",
    "- categories - list of categories the product belongs to\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### TO DO LIST\n",
    "\n",
    "In the followings statements, 'extracted' means filtered with the thema : products/reviews associated to bio/ecology/renewable etc...\n",
    "\n",
    "- Choose category to focus on : Books ?  / Cinema Movies / Kindle Store / Home Kitchen / Health Personal Care (K) / Tools Home Improvement (K) / Grocery Food  / Tools Home (K)\n",
    "- Show Proportion of extracted data compared to the full data (of the category)\n",
    "- Comparison of extracted data between categories (which one contains the most related products/review interest)\n",
    "- Distribution Price of extracted data (per category) --> Compare between category and with not extracted data in the same category\n",
    "- Distribution salesRank of extracted data (best per category, mean, proportion of 10% first, 20%first etc...) --> Compare between category and with not extracted data in the same category\n",
    "\n",
    "- __Keywords__ : How to efficiently implement the selection of related data ? Currently with a list of key words, can use regexp, better writing of keywords etc.. ?\n",
    "\n",
    "- Associate Metadata with Reviews : __Join__\n",
    "> - Extract year of 1st review (which will give the publication year of the product -approximately-)\n",
    "> - Histograms number of extracted products per year \n",
    "> - Histograms number of extracted reviews per year\n",
    "> - Nb of reviews per product per category --> Distribution, compare between categories and with not extracted data to see if reviewers are more inerested/active with our thema products compared to others\n",
    "> - Helplful note : Compare between categories / Overall\n",
    "> - Mean rating product : Compare with other products\n",
    "\n",
    "\n",
    "- __Prediction__\n",
    "> - Nb of products for following years (Linear Regression)\n",
    "> - Sentiment Analysis on Reviews (Experiment ?)\n",
    "> - Prediction overall on price for following years ? (LR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql.types import TimestampType\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql import SQLContext\n",
    "import pyspark.sql.functions as sqlf\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Data collection and preprocessing\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will perform the whole data processing.\n",
    "\n",
    "To simplify what is presented here, we have decided to perform all these steps for each category in the **separate pyton scripts**.\n",
    "\n",
    "<br>\n",
    "\n",
    "For each category, we will proceed as follows:\n",
    "- Import the meta data and reviews that have been downloaded as `json` files\n",
    "- Extract the relevant and writtable features of meta data\n",
    "- Save it as a parquet file of the form **`\"category\"_datacleaned`**\n",
    "- We then do the same with the reviews and save a parquet file of the form **`\"category\"_reviews`**\n",
    "- Next, we **filter the data we have to only keep articles related to ecology/bio/renewable etc...**\n",
    "- Finally, we join the metadata and review dataset using the product ID, and create a finale parquet file of the form **`\"category\"_review_product_join`**\n",
    "\n",
    "<br>\n",
    "\n",
    "Therefore, all you need to do now is execute all the scripts to automatically generate all the parquetfiles that will be used in tis notebook.\n",
    "\n",
    ">Note that once these files have been created, we can skip this part to gain a lot of time.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grocery and Gourmet Food**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i \"data_collection_grocery_food\"\n",
    "# Run the # Run the data_collection_grocery_food.py file .py file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Healthcare**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i \"data_collection_healthcare\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Patio Lawn and Garden**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i \"data_collection_lawn_garden\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Books**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i \"data_collection_books\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "### Loading data\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our scripts have generated the files, let's just fetch the data that will allow us to do our analysis.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\" global warming\", \" solar energy\", \" recycling \", \" pollution \", \"solar power\", \" endangered species\", \"air pollution\", \\\n",
    "\" water pollution\", \" wind energy\", \" climate change\", \" wind power\", \" recycle \", \" deforestation\", \" greenhouse effect\", \"environment\", \\\n",
    "\" sustainability \", \" natural resources\", \"alternative energy\", \" climate \", \"global warming\", \"renewable energy\", \" ecology\", \"composting\", \\\n",
    "\" carbon footprint\", \" bio \", \" biosphere \", \" renewable \"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grocery and Gourmet Food**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery_food_datacleaned = spark.read.parquet(\"meta_Grocery_and_Gourmet_Food.parquet\")\n",
    "grocery_food_reviews = spark.read.parquet(\"reviews_Grocery_and_Gourmet_Food.parquet\")\n",
    "grocery_food_review_product_join = spark.read.parquet(\"Grocery_and_Gourmet_Food.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery_filter_products_bio = grocery_food_datacleaned.rdd.filter(lambda r: (r[6] != None) &  (r[3] != None)) \\\n",
    "                    .filter(lambda r: (any(word in r[6].lower() for word in keywords)) | (any(word in r[3].lower() for word in keywords)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Healthcare**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthcare_datacleaned = spark.read.parquet(\"meta_HealthPersonalCare.parquet\")\n",
    "healthcare_reviews = spark.read.parquet(\"reviews_HealthPersonalCare.parquet\")\n",
    "healthcare_review_product_join = spark.read.parquet(\"HealthPersonalCare_joined.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthcare_filter_products_bio = healthcare_datacleaned.rdd.filter(lambda r: (r[6] != None) &  (r[3] != None)) \\\n",
    "                    .filter(lambda r: (any(word in r[6].lower() for word in keywords)) | (any(word in r[3].lower() for word in keywords)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Patio Lawn and Garden**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patiolawn_garden_datacleaned = spark.read.parquet(\"meta_PatioLawnGarden.parquet\")\n",
    "patiolawn_garden_reviews = spark.read.parquet(\"reviews_PatioLawnGarden.parquet\")\n",
    "patiolawn_garden_review_product_join = spark.read.parquet(\"PatioLawnGarden_joined.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patiolawn_garden_filter_products_bio = patiolawn_garden_datacleaned.rdd.filter(lambda r: (r[6] != None) &  (r[3] != None)) \\\n",
    "                    .filter(lambda r: (any(word in r[6].lower() for word in keywords)) | (any(word in r[3].lower() for word in keywords)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Books**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_datacleaned = spark.read.parquet(\"meta_Books.parquet\")\n",
    "books_reviews = spark.read.parquet(\"reviews_Books.parquet\")\n",
    "books_review_product_join = spark.read.parquet(\"joined_Books.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_filter_products_bio = books_datacleaned.rdd.filter(lambda r: (r[5] != None) &  (r[3] != None)) \\\n",
    "                    .filter(lambda r: (any(word in r[5].lower() for word in keywords)) | (any(word in r[3].lower() for word in keywords)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "### Analysis\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's start analyzing the data we extracted above.\n",
    "\n",
    "We will carry out different analyses, and each time apply it to all the categories studied to compare them with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**1) Grocery and Gourmet Food**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"GROCERY FOOD : Number of products : \" + str(grocery_food_datacleaned.rdd.count()) )\n",
    "print(\"GROCERY FOOD : Number of products related to ecology/bio/renewable etc... : \" + str(grocery_filter_products_bio.count()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportion of extracted data related to ecology/bio/renewable compared to the full data that was available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'Data samples related to ecology/bio/renewable', 'Other'; colors_graph = ['skyblue', 'lightcoral']\n",
    "plt.pie([grocery_food_filter_products_bio.count(), grocery_food_datacleaned.rdd.count()-grocery_food_filter_products_bio.count()], autopct='%1.1f%%', explode=(0.1, 0), labels=labels, colors=colors_graph)\n",
    "plt.title('Grocery and Gourmet Food data'); plt.axis('equal'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at one entry that was extracted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grocery_food_filter_products_bio.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Healthcare**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"HEALTHCARE : Number of products : \" + str(healthcare_datacleaned.rdd.count()) )\n",
    "print(\"HEALTHCARE : Number of products related to ecology/bio/renewable etc... : \" + str(healthcare_filter_products_bio.count()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'Data samples related to ecology/bio/renewable', 'Other'; colors_graph = ['skyblue', 'lightcoral']\n",
    "plt.pie([healthcare_filter_products_bio.count(), healthcare_datacleaned.rdd.count()-healthcare_filter_products_bio.count()], autopct='%1.1f%%', explode=(0.1, 0), labels=labels, colors=colors_graph)\n",
    "plt.title('Healthcare data'); plt.axis('equal'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Patio Lawn and Garden**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PATIOLAWN - GARDEN : Number of products : \" + str(patiolawn_garden_datacleaned.rdd.count()) )\n",
    "print(\"PATIOLAWN - GARDEN : Number of products related to ecology/bio/renewable etc... : \" + str(patiolawn_garden_filter_products_bio.count()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'Data samples related to ecology/bio/renewable', 'Other'; colors_graph = ['skyblue', 'lightcoral']\n",
    "plt.pie([patiolawn_garden_filter_products_bio.count(), patiolawn_garden_datacleaned.rdd.count()-patiolawn_garden_filter_products_bio.count()], autopct='%1.1f%%', explode=(0.1, 0), labels=labels, colors=colors_graph)\n",
    "plt.title('PatioLawn Garden data'); plt.axis('equal'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Books**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BOOKS : Number of products : \" + str(books_datacleaned.rdd.count()) )\n",
    "print(\"BOOKS : Number of products related to ecology/bio/renewable etc... : \" + str(books_filter_products_bio.count()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'Data samples related to ecology/bio/renewable', 'Other'; colors_graph = ['skyblue', 'lightcoral']\n",
    "plt.pie([books_filter_products_bio.count(), books_datacleaned.rdd.count()-books_filter_products_bio.count()], autopct='%1.1f%%', explode=(0.1, 0), labels=labels, colors=colors_graph)\n",
    "plt.title('Books data'); plt.axis('equal'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's see the evolution of the trend in products by year:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**1) Grocery and Gourmet Food**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grocerybio_firstrev = grocery_food_review_product_join.groupBy(\"asin\").agg(sqlf.min(\"unixReviewTime\"))\n",
    "grocerybio_firstrev_pd = grocerybio_firstrev.toPandas()\n",
    "grocerybio_firstrev_pd['Year'] = pd.to_datetime(grocerybio_firstrev_pd['min(unixReviewTime)'],unit='s').map(lambda x: x.year)\n",
    "\n",
    "groceryall_firstrev = grocery_food_reviews.groupBy(\"asin\").agg(sqlf.min(\"unixReviewTime\"))\n",
    "groceryall_firstrev_pd = groceryall_firstrev.toPandas()\n",
    "groceryall_firstrev_pd['Year'] = pd.to_datetime(groceryall_firstrev_pd['min(unixReviewTime)'],unit='s').map(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "fig.set_size_inches(16,4)\n",
    "\n",
    "\n",
    "grocery_firstrev_pd.hist(\"Year\", color=\"skyblue\", log=True,bins=10,ax=axes[0])\n",
    "plt.title('Evolution of the trend in the products')\n",
    "\n",
    "\n",
    "globalyear_reviews_Pandas.hist(\"Year\", log=True, color=\"skyblue\", bins=14, ax=axes[1])\n",
    "plt.title('Evolution of the trend in the reviews')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Healthcare**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthcarebio_firstrev = healthcare_review_product_join.groupBy(\"asin\").agg(sqlf.min(\"unixReviewTime\"))\n",
    "healthcarebio_firstrev_pd = healthcarebio_firstrev.toPandas()\n",
    "healthcarebio_firstrev_pd['Year'] = pd.to_datetime(healthcarebio_firstrev_pd['min(unixReviewTime)'],unit='s').map(lambda x: x.year)\n",
    "\n",
    "healthcareall_firstrev = healthcare_reviews.groupBy(\"asin\").agg(sqlf.min(\"unixReviewTime\"))\n",
    "healthcareall_firstrev_pd = healthcareall_firstrev.toPandas()\n",
    "healthcareall_firstrev_pd['Year'] = pd.to_datetime(healthcareall_firstrev_pd['min(unixReviewTime)'],unit='s').map(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "fig.set_size_inches(16,4)\n",
    "\n",
    "\n",
    "healthcarebio_firstrev_pd.hist(\"Year\", color=\"skyblue\", log=True,bins=10,ax=axes[0])\n",
    "plt.title('Evolution of the trend in the products')\n",
    "\n",
    "\n",
    "healthcareall_firstrev_pd.hist(\"Year\", log=True, color=\"skyblue\", bins=14, ax=axes[1])\n",
    "plt.title('Evolution of the trend in the reviews')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) PatioLawn Garden**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gardenbio_firstrev = patiolawn_garden_review_product_join.groupBy(\"asin\").agg(sqlf.min(\"unixReviewTime\"))\n",
    "gardenbio_firstrev_pd = gardenbio_firstrev.toPandas()\n",
    "gardenbio_firstrev_pd['Year'] = pd.to_datetime(gardenbio_firstrev_pd['min(unixReviewTime)'],unit='s').map(lambda x: x.year)\n",
    "\n",
    "gardeneall_firstrev = patiolawn_garden_reviews.groupBy(\"asin\").agg(sqlf.min(\"unixReviewTime\"))\n",
    "gardeneall_firstrev_pd = gardeneall_firstrev.toPandas()\n",
    "gardeneall_firstrev_pd['Year'] = pd.to_datetime(gardeneall_firstrev_pd['min(unixReviewTime)'],unit='s').map(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "fig.set_size_inches(16,4)\n",
    "\n",
    "\n",
    "gardenbio_firstrev_pd.hist(\"Year\", color=\"skyblue\", log=True,bins=10,ax=axes[0])\n",
    "plt.title('Evolution of the trend in the products')\n",
    "\n",
    "\n",
    "gardeneall_firstrev_pd.hist(\"Year\", log=True, color=\"skyblue\", bins=14, ax=axes[1])\n",
    "plt.title('Evolution of the trend in the reviews')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Books**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booksbio_firstrev = books_review_product_join.groupBy(\"asin\").agg(sqlf.min(\"unixReviewTime\"))\n",
    "booksbio_firstrev_pd = booksbio_firstrev.toPandas()\n",
    "booksbio_firstrev_pd['Year'] = pd.to_datetime(booksbio_firstrev_pd['min(unixReviewTime)'],unit='s').map(lambda x: x.year)\n",
    "\n",
    "booksall_firstrev = books_reviews.groupBy(\"asin\").agg(sqlf.min(\"unixReviewTime\"))\n",
    "booksall_firstrev_pd = booksall_firstrev.toPandas()\n",
    "booksall_firstrev_pd['Year'] = pd.to_datetime(booksall_firstrev_pd['min(unixReviewTime)'],unit='s').map(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "fig.set_size_inches(16,4)\n",
    "\n",
    "\n",
    "booksbio_firstrev_pd.hist(\"Year\", color=\"skyblue\", log=True,bins=17,ax=axes[0])\n",
    "plt.title('Evolution of the trend in the products')\n",
    "\n",
    "\n",
    "booksall_firstrev_pd.hist(\"Year\", log=True, color=\"skyblue\", bins=18, ax=axes[1])\n",
    "plt.title('Evolution of the trend in the reviews')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Let's now see distribution of reviews per products for each of the categories:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Grocery Food**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grocerybio_nbrev_perproduct=  grocery_food_review_product_join.rdd.map(lambda r: [r[0],1]) \\\n",
    "            .reduceByKey(lambda a,b: a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grocerybio_nbreviews_DF = spark.createDataFrame(grocerybio_nbrev_perproduct, ['productID','freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grocerybio_nbreviews_Pandas = nbreviews_DF.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, sharex=True, sharey=True); fig.set_size_inches(16,5)\n",
    "grocerybio_nbreviews_Pandas.hist(log=True, bins = 100, color=\"skyblue\", cumulative=-1, ax=axes)\n",
    "axes.set_xlabel(\"Nb of reviews/ Product\")\n",
    "axes.set_ylabel(\"Frequency\")\n",
    "axes.set_title(\"Nb of reviews/ Product Distribution Associated to Ecology/Bio etc..\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Healthcare**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthcarebio_nbrev_perproduct=  healthcare_review_product_join.rdd.map(lambda r: [r[0],1]) \\\n",
    "            .reduceByKey(lambda a,b: a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthcarebio_nbreviews_DF = spark.createDataFrame(healthcarebio_nbrev_perproduct, ['productID','freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthcarebio_nbreviews_pd = healthcarebio_nbreviews_DF.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, sharex=True, sharey=True); fig.set_size_inches(16,5)\n",
    "healthcarebio_nbreviews_pd.hist(log=True, bins = 100, color=\"skyblue\", cumulative=-1, ax=axes)\n",
    "axes.set_xlabel(\"Nb of reviews/ Product\")\n",
    "axes.set_ylabel(\"Frequency\")\n",
    "axes.set_title(\"Nb of reviews/ Product Distribution Associated to Ecology/Bio etc..\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Patio Lawn Garden**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gardenbio_nbrev_perproduct=  patiolawn_garden_review_product_join.rdd.map(lambda r: [r[0],1]) \\\n",
    "            .reduceByKey(lambda a,b: a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gardenbio_nbreviews_DF = spark.createDataFrame(gardenbio_nbrev_perproduct, ['productID','freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gardenbio_nbreviews_pd = gardenbio_nbreviews_DF.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, sharex=True, sharey=True); fig.set_size_inches(16,5)\n",
    "gardenbio_nbreviews_pd.hist(log=True, bins = 100, color=\"skyblue\", cumulative=-1, ax=axes)\n",
    "axes.set_xlabel(\"Nb of reviews/ Product\")\n",
    "axes.set_ylabel(\"Frequency\")\n",
    "axes.set_title(\"Nb of reviews/ Product Distribution Associated to Ecology/Bio etc..\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gardenall_nbrev_perproduct=  patiolawn_garden_reviews.rdd.map(lambda r: [r[0],1]) \\\n",
    "            .reduceByKey(lambda a,b: a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gardenall_nbreviews_DF = spark.createDataFrame(gardenall_nbrev_perproduct, ['productID','freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gardenall_nbreviews_pd = gardenall_nbreviews_DF.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, sharex=True, sharey=True); fig.set_size_inches(16,5)\n",
    "gardenall_nbreviews_pd.hist(log=True, bins = 100, color=\"skyblue\", cumulative=-1, ax=axes)\n",
    "axes.set_xlabel(\"Nb of reviews/ Product\")\n",
    "axes.set_ylabel(\"Frequency\")\n",
    "axes.set_title(\"Nb of reviews/ Product Distribution Associated to Ecology/Bio etc..\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Books**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booksbio_nbrev_perproduct=  books_review_product_join.rdd.map(lambda r: [r[0],1]) \\\n",
    "            .reduceByKey(lambda a,b: a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booksbio_nbreviews_DF = spark.createDataFrame(booksbio_nbrev_perproduct, ['productID','freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booksbio_nbreviews_Pandas = booksbio_nbreviews_DF.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, sharex=True, sharey=True); fig.set_size_inches(16,5)\n",
    "booksbio_nbreviews_Pandas.hist(log=True, bins = 100, color=\"skyblue\", cumulative=-1, ax=axes)\n",
    "axes.set_xlabel(\"Nb of reviews/ Product\")\n",
    "axes.set_ylabel(\"Frequency\")\n",
    "axes.set_title(\"Nb of reviews/ Product Distribution Associated to Ecology/Bio etc..\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "### Predictions\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
